{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing regression models\n",
    "\n",
    "We need to be able to compare our regression models in order to test our hypotheses, e.g.:\n",
    "* What is a better predictor of app **latency** / **throughput** - **number of instances** on the machine or **CPU usage** of the machine?\n",
    "* Is it worth to add **CPU usage** to the model?\n",
    "* What are the best features for predicting **latency** / **throughput**?\n",
    "\n",
    "This notebook covers some measures that help to answer those questions, using data from experiment `linpack_12x20` as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbtool_time</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>app_latency</th>\n",
       "      <th>app_throughput</th>\n",
       "      <th>cpu</th>\n",
       "      <th>instances_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.8908</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.4394</td>\n",
       "      <td>427.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.2988</td>\n",
       "      <td>1244.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>224.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.4386</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>284.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.4588</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cbtool_time  cpu_time  app_latency  app_throughput     cpu  instances_n\n",
       "0         44.0      44.0          NaN         32.8908   180.0          1.0\n",
       "1        104.0     104.0          NaN         33.4394   427.0          1.0\n",
       "2        164.0     165.0          NaN         33.2988  1244.0          1.0\n",
       "3        224.0     225.0          NaN         33.4386  2035.0          1.0\n",
       "4        284.0     285.0          NaN         33.4588  2034.0          1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import (\n",
    "    add_instances_n,\n",
    "    draw_regression_graph,\n",
    "    fit_regression,\n",
    "    get_experiments_data,\n",
    "    get_attach_indexes,\n",
    "    get_data_with_cpu,\n",
    ")\n",
    "\n",
    "experiment_name = 'linpack_12x20'\n",
    "\n",
    "exp_name, df = next(get_data_with_cpu(experiment_name, instances_n=12))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-Squared\n",
    "\n",
    "**R-squared** ($R^2$) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n",
    "\n",
    "So, if the $R^2$ of a model is $0.50$, then approximately half of the observed variation can be explained by the model's inputs.\n",
    "\n",
    "## Adjusted R-Squared\n",
    "\n",
    "R-Squared only works as intended in a simple linear regression model with one explanatory variable. With a multiple regression made up of several independent variables, the R-Squared must be adjusted. The **adjusted R-squared** compares the descriptive power of regression models that include diverse numbers of predictors. Every predictor added to a model increases R-squared and never decreases it. Thus, a model with more terms may seem to have a better fit just for the fact that it has more terms, while the adjusted R-squared compensates for the addition of variables and only increases if the new term enhances the model above what would be obtained by probability and decreases when a predictor enhances the model less than what is predicted by chance. In an overfitting condition, an incorrectly high value of R-squared is obtained, even when the model actually has a decreased ability to predict. This is not the case with the adjusted R-squared.\n",
    "\n",
    "## Akaike information criterion (AIC)\n",
    "\n",
    "**Akaike information criterion (AIC)** is an estimator of out-of-sample prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection.\n",
    "\n",
    "AIC is founded on information theory. When a statistical model is used to represent the process that generated the data, the representation will almost never be exact; so some information will be lost by using the model to represent the process. AIC estimates the relative amount of information lost by a given model: the less information a model loses, the higher the quality of that model (**the lower the better**).\n",
    "\n",
    "In estimating the amount of information lost by a model, AIC deals with the trade-off between the goodness of fit of the model and the simplicity of the model. In other words, AIC deals with both the risk of overfitting and the risk of underfitting.\n",
    "\n",
    "## Bayesian information criterion (BIC)\n",
    "\n",
    "The formula for the **Bayesian information criterion (BIC)** is similar to the formula for AIC, but with a different penalty for the number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "### Regression `app_throughput` ~ `instances_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         app_throughput   R-squared:                       0.928\n",
      "Model:                            OLS   Adj. R-squared:                  0.928\n",
      "Method:                 Least Squares   F-statistic:                     1977.\n",
      "Date:                Wed, 17 Jun 2020   Prob (F-statistic):           2.14e-89\n",
      "Time:                        02:55:01   Log-Likelihood:                -341.02\n",
      "No. Observations:                 155   AIC:                             686.0\n",
      "Df Residuals:                     153   BIC:                             692.1\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      34.5753      0.332    104.068      0.000      33.919      35.232\n",
      "instances_n    -2.3285      0.052    -44.465      0.000      -2.432      -2.225\n",
      "==============================================================================\n",
      "Omnibus:                        6.219   Durbin-Watson:                   1.122\n",
      "Prob(Omnibus):                  0.045   Jarque-Bera (JB):                6.187\n",
      "Skew:                          -0.489   Prob(JB):                       0.0454\n",
      "Kurtosis:                       3.010   Cond. No.                         12.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_throughput ~ instances_n')\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression `app_throughput` ~ `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         app_throughput   R-squared:                       0.908\n",
      "Model:                            OLS   Adj. R-squared:                  0.907\n",
      "Method:                 Least Squares   F-statistic:                     1511.\n",
      "Date:                Wed, 17 Jun 2020   Prob (F-statistic):           3.39e-81\n",
      "Time:                        02:55:01   Log-Likelihood:                -360.14\n",
      "No. Observations:                 155   AIC:                             724.3\n",
      "Df Residuals:                     153   BIC:                             730.4\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     38.2653      0.462     82.792      0.000      37.352      39.178\n",
      "cpu           -0.0022   5.53e-05    -38.878      0.000      -0.002      -0.002\n",
      "==============================================================================\n",
      "Omnibus:                        0.241   Durbin-Watson:                   1.215\n",
      "Prob(Omnibus):                  0.887   Jarque-Bera (JB):                0.182\n",
      "Skew:                           0.083   Prob(JB):                        0.913\n",
      "Kurtosis:                       2.980   Cond. No.                     1.93e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.93e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_throughput ~ cpu')\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression `app_throughput` ~ `instances_n` + `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         app_throughput   R-squared:                       0.943\n",
      "Model:                            OLS   Adj. R-squared:                  0.942\n",
      "Method:                 Least Squares   F-statistic:                     1255.\n",
      "Date:                Wed, 17 Jun 2020   Prob (F-statistic):           3.18e-95\n",
      "Time:                        02:55:01   Log-Likelihood:                -323.24\n",
      "No. Observations:                 155   AIC:                             652.5\n",
      "Df Residuals:                     152   BIC:                             661.6\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      36.3838      0.414     87.793      0.000      35.565      37.203\n",
      "instances_n    -1.4395      0.150     -9.628      0.000      -1.735      -1.144\n",
      "cpu            -0.0009      0.000     -6.262      0.000      -0.001      -0.001\n",
      "==============================================================================\n",
      "Omnibus:                        3.982   Durbin-Watson:                   1.542\n",
      "Prob(Omnibus):                  0.137   Jarque-Bera (JB):                3.511\n",
      "Skew:                          -0.301   Prob(JB):                        0.173\n",
      "Kurtosis:                       3.425   Cond. No.                     2.23e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.23e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_throughput ~ instances_n + cpu')\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "As we can see, the results are:\n",
    "\n",
    "`app_throughput` ~ `instances_n`:\n",
    "* Adj. R-squared: `0.928`\n",
    "* AIC: `686.0`\n",
    "* BIC: `692.1`\n",
    "\n",
    "`app_throughput` ~ `cpu`:\n",
    "* Adj. R-squared: `0.907`\n",
    "* AIC: `724.3`\n",
    "* BIC: `730.4`\n",
    "\n",
    "`app_throughput` ~ `instances_n` + `cpu`:\n",
    "* Adj. R-squared: `0.942`\n",
    "* AIC: `652.5`\n",
    "* BIC: `661.6`\n",
    "\n",
    "We can conclude that the model with only `instances_n` is **bettter** than the model with only `cpu`, because **Adj. R-squared** is **higher** and **AIC** and **BIC** are **lower**.\n",
    "\n",
    "Although in this case, the variable `cpu` is still useful, because model with both `instances_n` and `cpu` is better than models with single variables.\n",
    "\n",
    "It should be pointed out, that those conclusions are **not true for every experiment**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson correlation coefficient\n",
    "\n",
    "**Pearson correlation coefficient** is a statistic that measures linear correlation between two variables X and Y. It has a value between +1 and −1, where 1 is total positive linear correlation, 0 is no linear correlation, and −1 is total negative linear correlation\n",
    "\n",
    "## Spearman's rank correlation coefficient\n",
    "\n",
    "**Spearman's rank correlation coefficient** is a nonparametric measure of rank correlation (statistical dependence between the rankings of two variables). It assesses how well the relationship between two variables can be described using a monotonic function.\n",
    "\n",
    "## Mutual information\n",
    "\n",
    "**Mutual information (MI)** of two random variables is a measure of the mutual dependence between the two variables. More specifically, it quantifies the \"amount of information\" (in units such as shannons, commonly called bits) obtained about one random variable through observing the other random variable. The concept of mutual information is intricately linked to that of entropy of a random variable, a fundamental notion in information theory that quantifies the expected \"amount of information\" held in a random variable.\n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson between app_throughput and instances_n: -0.9634\n",
      "Pearson between app_throughput and cpu: -0.9529\n",
      "Pearson between instances_n and cpu: 0.9496\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "features = ['app_throughput', 'instances_n', 'cpu']\n",
    "\n",
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    corr = pearsonr(df[feat_a], df[feat_b])[0]\n",
    "    print(f'Pearson between {feat_a} and {feat_b}: {corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmanr between app_throughput and instances_n: -0.9788\n",
      "Spearmanr between app_throughput and cpu: -0.9589\n",
      "Spearmanr between instances_n and cpu: 0.9846\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    corr = spearmanr(df[feat_a], df[feat_b])[0]\n",
    "    print(f'Spearmanr between {feat_a} and {feat_b}: {corr:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we confirmed our hypothesis that `instances_n` is a better explanatory variable than `cpu`, because there is stronger correlation between `app_throughput` and `instances_n` than between `app_throughput` and `cpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information between app_throughput and instances_n: 2.4209\n",
      "Mutual information between app_throughput and cpu: 4.9898\n",
      "Mutual information between instances_n and cpu: 2.4030\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "\n",
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    mi = mutual_info_score(df[feat_a], df[feat_b])\n",
    "    print(f'Mutual information between {feat_a} and {feat_b}: {mi:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, mutual information is higher for `app_throughput` and `cpu`.\n",
    "\n",
    "This would suggest that the dependence between `app_throughput` and `cpu` is still strong, but it's more **non-linear** than between `app_throughput` and `instances_n`.\n",
    "\n",
    "That's why those measures are complementary and should both be looked at."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
