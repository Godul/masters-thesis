{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing regression models\n",
    "\n",
    "We need to be able to compare our regression models in order to test our hypotheses, e.g.:\n",
    "* What is a better predictor of app **latency** / **throughput** - **number of instances** on the machine or **CPU usage** of the machine?\n",
    "* Is it worth to add **CPU usage** to the model?\n",
    "* What are the best features for predicting **latency** / **throughput**?\n",
    "\n",
    "This notebook covers some measures that help to answer those questions, using data from experiment `linpack_12x20` as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-Squared\n",
    "\n",
    "**R-squared** ($R^2$) is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.\n",
    "\n",
    "So, if the $R^2$ of a model is $0.50$, then approximately half of the observed variation can be explained by the model's inputs.\n",
    "\n",
    "## Adjusted R-Squared\n",
    "\n",
    "R-Squared only works as intended in a simple linear regression model with one explanatory variable. With a multiple regression made up of several independent variables, the R-Squared must be adjusted. The **adjusted R-squared** compares the descriptive power of regression models that include diverse numbers of predictors. Every predictor added to a model increases R-squared and never decreases it. Thus, a model with more terms may seem to have a better fit just for the fact that it has more terms, while the adjusted R-squared compensates for the addition of variables and only increases if the new term enhances the model above what would be obtained by probability and decreases when a predictor enhances the model less than what is predicted by chance. In an overfitting condition, an incorrectly high value of R-squared is obtained, even when the model actually has a decreased ability to predict. This is not the case with the adjusted R-squared.\n",
    "\n",
    "## Akaike information criterion (AIC)\n",
    "\n",
    "**Akaike information criterion (AIC)** is an estimator of out-of-sample prediction error and thereby relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection.\n",
    "\n",
    "AIC is founded on information theory. When a statistical model is used to represent the process that generated the data, the representation will almost never be exact; so some information will be lost by using the model to represent the process. AIC estimates the relative amount of information lost by a given model: the less information a model loses, the higher the quality of that model (**the lower the better**).\n",
    "\n",
    "In estimating the amount of information lost by a model, AIC deals with the trade-off between the goodness of fit of the model and the simplicity of the model. In other words, AIC deals with both the risk of overfitting and the risk of underfitting.\n",
    "\n",
    "## Bayesian information criterion (BIC)\n",
    "\n",
    "The formula for the **Bayesian information criterion (BIC)** is similar to the formula for AIC, but with a different penalty for the number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - linpack 12x20min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbtool_time</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>app_latency</th>\n",
       "      <th>app_throughput</th>\n",
       "      <th>cpu</th>\n",
       "      <th>memory</th>\n",
       "      <th>instances_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1592311591</td>\n",
       "      <td>1592311594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.3820</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>4.546589e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1592311651</td>\n",
       "      <td>1592311654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.3700</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>4.547256e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1592311711</td>\n",
       "      <td>1592311715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.3523</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>4.545925e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1592311771</td>\n",
       "      <td>1592311775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.2720</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>4.546154e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1592311831</td>\n",
       "      <td>1592311836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.1085</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>4.545212e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cbtool_time    cpu_time  app_latency  app_throughput     cpu        memory  \\\n",
       "0  1592311591  1592311594          NaN         33.3820  2035.0  4.546589e+09   \n",
       "1  1592311651  1592311654          NaN         33.3700  2034.0  4.547256e+09   \n",
       "2  1592311711  1592311715          NaN         33.3523  2034.0  4.545925e+09   \n",
       "3  1592311771  1592311775          NaN         32.2720  2057.0  4.546154e+09   \n",
       "4  1592311831  1592311836          NaN         33.1085  2044.0  4.545212e+09   \n",
       "\n",
       "   instances_n  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from helpers.helpers_old import (\n",
    "    fit_regression,\n",
    "    get_data_with_metrics,\n",
    ")\n",
    "\n",
    "experiments_path = '../../data'\n",
    "experiment_name = 'linpack_12x20'\n",
    "\n",
    "exp_name, df = next(get_data_with_metrics(experiment_name, experiments_path, instances_n=12))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression `app_throughput` ~ `instances_n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_measures(results):\n",
    "    print(f'Adj. R-squared: {results.rsquared_adj:.4f}')\n",
    "    print(f'AIC: {results.aic:.5f}')\n",
    "    print(f'BIC: {results.bic:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fit_regression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cec422adaf71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'app_throughput ~ instances_n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_measures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fit_regression' is not defined"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_throughput ~ instances_n')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression `app_throughput` ~ `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj. R-squared: 0.9239\n",
      "AIC: 654.52017\n",
      "BIC: 660.55473\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_throughput ~ cpu')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression `app_throughput` ~ `instances_n` + `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj. R-squared: 0.9452\n",
      "AIC: 606.04180\n",
      "BIC: 615.09364\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_throughput ~ instances_n + cpu')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "We can conclude that the model with only `instances_n` is **slightly worse** than the model with only `cpu`, because **Adj. R-squared** is **lower** and **AIC** and **BIC** are **higher**.\n",
    "\n",
    "Although in this case, the variable `instances_n` is still useful, because model with both `instances_n` and `cpu` is better than models with single variables.\n",
    "\n",
    "It should be pointed out, that those conclusions are **not true for every experiment**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson correlation coefficient\n",
    "\n",
    "**Pearson correlation coefficient** is a statistic that measures linear correlation between two variables X and Y. It has a value between +1 and −1, where 1 is total positive linear correlation, 0 is no linear correlation, and −1 is total negative linear correlation\n",
    "\n",
    "## Spearman's rank correlation coefficient\n",
    "\n",
    "**Spearman's rank correlation coefficient** is a nonparametric measure of rank correlation (statistical dependence between the rankings of two variables). It assesses how well the relationship between two variables can be described using a monotonic function.\n",
    "\n",
    "## Mutual information\n",
    "\n",
    "**Mutual information (MI)** of two random variables is a measure of the mutual dependence between the two variables. More specifically, it quantifies the \"amount of information\" (in units such as shannons, commonly called bits) obtained about one random variable through observing the other random variable. The concept of mutual information is intricately linked to that of entropy of a random variable, a fundamental notion in information theory that quantifies the expected \"amount of information\" held in a random variable.\n",
    "\n",
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson between app_throughput and instances_n: -0.9609\n",
      "Pearson between app_throughput and cpu: -0.9615\n",
      "Pearson between app_throughput and memory: -0.9197\n",
      "Pearson between instances_n and cpu: 0.9535\n",
      "Pearson between instances_n and memory: 0.9648\n",
      "Pearson between cpu and memory: 0.8998\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "features = ['app_throughput', 'instances_n', 'cpu', 'memory']\n",
    "\n",
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    corr = pearsonr(df[feat_a], df[feat_b])[0]\n",
    "    print(f'Pearson between {feat_a} and {feat_b}: {corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmanr between app_throughput and instances_n: -0.9753\n",
      "Spearmanr between app_throughput and cpu: -0.9671\n",
      "Spearmanr between app_throughput and memory: -0.9537\n",
      "Spearmanr between instances_n and cpu: 0.9852\n",
      "Spearmanr between instances_n and memory: 0.9722\n",
      "Spearmanr between cpu and memory: 0.9589\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    corr = spearmanr(df[feat_a], df[feat_b])[0]\n",
    "    print(f'Spearmanr between {feat_a} and {feat_b}: {corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information between app_throughput and instances_n: 2.3679\n",
      "Mutual information between app_throughput and cpu: 4.9622\n",
      "Mutual information between app_throughput and memory: 5.0081\n",
      "Mutual information between instances_n and cpu: 2.3587\n",
      "Mutual information between instances_n and memory: 2.3679\n",
      "Mutual information between cpu and memory: 4.9530\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "\n",
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    mi = mutual_info_score(df[feat_a], df[feat_b])\n",
    "    print(f'Mutual information between {feat_a} and {feat_b}: {mi:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example - wrk 12x20min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cbtool_time</th>\n",
       "      <th>cpu_time</th>\n",
       "      <th>app_latency</th>\n",
       "      <th>app_throughput</th>\n",
       "      <th>cpu</th>\n",
       "      <th>memory</th>\n",
       "      <th>instances_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1591802843</td>\n",
       "      <td>1591802848</td>\n",
       "      <td>15.24</td>\n",
       "      <td>8880.0</td>\n",
       "      <td>7167.0</td>\n",
       "      <td>4.690260e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1591802907</td>\n",
       "      <td>1591802908</td>\n",
       "      <td>10.08</td>\n",
       "      <td>20180.0</td>\n",
       "      <td>5906.0</td>\n",
       "      <td>4.676293e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1591802971</td>\n",
       "      <td>1591802969</td>\n",
       "      <td>20.20</td>\n",
       "      <td>5360.0</td>\n",
       "      <td>7869.0</td>\n",
       "      <td>4.687049e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1591803449</td>\n",
       "      <td>1591803453</td>\n",
       "      <td>21.11</td>\n",
       "      <td>5340.0</td>\n",
       "      <td>6597.0</td>\n",
       "      <td>4.683792e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1591803513</td>\n",
       "      <td>1591803514</td>\n",
       "      <td>10.05</td>\n",
       "      <td>20140.0</td>\n",
       "      <td>6163.0</td>\n",
       "      <td>4.669866e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cbtool_time    cpu_time  app_latency  app_throughput     cpu        memory  \\\n",
       "0  1591802843  1591802848        15.24          8880.0  7167.0  4.690260e+09   \n",
       "1  1591802907  1591802908        10.08         20180.0  5906.0  4.676293e+09   \n",
       "2  1591802971  1591802969        20.20          5360.0  7869.0  4.687049e+09   \n",
       "3  1591803449  1591803453        21.11          5340.0  6597.0  4.683792e+09   \n",
       "4  1591803513  1591803514        10.05         20140.0  6163.0  4.669866e+09   \n",
       "\n",
       "   instances_n  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          1.0  \n",
       "4          1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'wrk_12x20'\n",
    "\n",
    "exp_name, df = next(get_data_with_metrics(experiment_name, experiments_path, instances_n=12))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj. R-squared: 0.9656\n",
      "AIC: 532.21507\n",
      "BIC: 537.02851\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_latency ~ instances_n')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj. R-squared: 0.7126\n",
      "AIC: 706.21839\n",
      "BIC: 711.03183\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_latency ~ cpu')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj. R-squared: 0.6287\n",
      "AIC: 727.22240\n",
      "BIC: 732.03584\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_latency ~ memory')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj. R-squared: 0.9778\n",
      "AIC: 497.10948\n",
      "BIC: 504.32964\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_latency ~ instances_n + cpu')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adj. R-squared: 0.9803\n",
      "AIC: 488.36683\n",
      "BIC: 497.99371\n"
     ]
    }
   ],
   "source": [
    "results = fit_regression(data=df, formula='app_latency ~ instances_n + cpu + memory')\n",
    "print_measures(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we can see that models with only `instances_n` are much better feature than those with only with `cpu` or only `memory`.\n",
    "\n",
    "At the same time, we see that adding `cpu` and `memory` to the models gives us a slight improvement.\n",
    "\n",
    "Let's check correlations and mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson between app_latency and instances_n: 0.9829\n",
      "Pearson between app_latency and cpu: 0.8463\n",
      "Pearson between app_latency and memory: 0.7958\n",
      "Pearson between instances_n and cpu: 0.7919\n",
      "Pearson between instances_n and memory: 0.7312\n",
      "Pearson between cpu and memory: 0.8598\n"
     ]
    }
   ],
   "source": [
    "features = ['app_latency', 'instances_n', 'cpu', 'memory']\n",
    "\n",
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    corr = pearsonr(df[feat_a], df[feat_b])[0]\n",
    "    print(f'Pearson between {feat_a} and {feat_b}: {corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman between app_latency and instances_n: 0.9926\n",
      "Spearman between app_latency and cpu: 0.9492\n",
      "Spearman between app_latency and memory: 0.5966\n",
      "Spearman between instances_n and cpu: 0.9594\n",
      "Spearman between instances_n and memory: 0.5989\n",
      "Spearman between cpu and memory: 0.5687\n"
     ]
    }
   ],
   "source": [
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    corr = spearmanr(df[feat_a], df[feat_b])[0]\n",
    "    print(f'Spearman between {feat_a} and {feat_b}: {corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information between app_latency and instances_n: 2.4569\n",
      "Mutual information between app_latency and cpu: 4.3898\n",
      "Mutual information between app_latency and memory: 4.3898\n",
      "Mutual information between instances_n and cpu: 2.4569\n",
      "Mutual information between instances_n and memory: 2.4569\n",
      "Mutual information between cpu and memory: 4.4067\n"
     ]
    }
   ],
   "source": [
    "for feat_a, feat_b in combinations(features, 2):\n",
    "    mi = mutual_info_score(df[feat_a], df[feat_b])\n",
    "    print(f'Mutual information between {feat_a} and {feat_b}: {mi:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson** correlation shows that there is a strong linear dependency between `app_latency` and `instances_n`. \n",
    "\n",
    "**Spearman** correlation shows that there is a significant, monotonic (not necessarily linear) dependency between `app_latency` and `cpu`.\n",
    "\n",
    "**Mutual information** shows that there is a significant (but not necessarily monotonic) dependency between `app_latency` and `memory`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
